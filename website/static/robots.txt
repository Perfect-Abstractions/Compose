# Robots.txt for Compose Documentation

# Allow all search engines to crawl the site
User-agent: *
Allow: /

# Disallow tag pages (low-value, duplicate content)
Disallow: /tags/

# Disallow search pages (dynamic, no-index content)
Disallow: /search

# Disallow any admin or internal paths
Disallow: /admin/
Disallow: /_next/
Disallow: /api/

# Allow important content paths explicitly
Allow: /docs
Allow: /blog
Allow: /

# Sitemap location
Sitemap: https://compose.diamonds/sitemap.xml

